<section class="sec-title" id="title-slide">
  <h2><b>Generative Agents <i>for</i> Simulation</b><br />LLM-Powered User Simulation</h2>
  <div>
    <div class="pub">
      <p>
        <b>Saber Zerhoudi</b>, Michael Granitzer
      </p>
      <p>
        <span class="pub-title">Generative Agents Navigating Digital Libraries</span>,
        <span class="pub-venue">ICADL 2024</span>
      </p>
    </div>
    <div class="pub">
      <p>
        <b>Saber Zerhoudi</b>, Michael Granitzer
      </p>
      <p>
        <span class="pub-title">PersonaRAG: Enhancing Retrieval-Augmented Generation Systems with
          User-Centric Agents</span>,
        <span class="pub-venue">SIGIR 2024</span>
      </p>
    </div>
  </div>
</section>

<section id="gen-agents-intro" data-auto-animate>
  <h2>Generative Agents</h2>
  <hr class="divider" />

  <p>
    With Large Language Models (LLMs), we can now create <b>Generative Agents</b>
    that exhibit complex, human-like behaviors.
  </p>
  <img class="fig fragment" data-fragment-index="1" src="img/gen_agents/smallville.png" style="margin-top: 0.5em" />
  <p class="caption fragment" data-fragment-index="1">
    A sandbox environment with twenty-five agents<sup>7</sup>. Agents perceive and record all experiences in a memory
    stream. Relevant memories are retrieved to determine actions, form long-term plans, and create higher-level
    reflections. These plans and reflections are then added to the memory stream for future use.
  </p>

  <hr class="divider" />
  <p class="footnote fragment" data-fragment-index="1">
    <sup>7</sup>Park J.S et al. "Generative agents: Interactive simulacra of human behavior". UIST
    2023.
  </p>
</section>

<section id="agent4dl-arch" data-auto-animate>
  <h2>Generative Agents</h2>
  <h4 style="margin-top: -0.5em; font-family: inherit;"><i>Simulating Academic Search</i></h4>
  <hr class="divider" />

  <p>
    <b>Agent4DL</b> is a framework for creating agents that simulate user search.<br><span class="fragment"
      data-fragment-index="1">
      It operates using <b>ReAct</b><sup>8</sup>: a continuous loop of
      reasoning and acting to achieve a goal.
    </span>
  </p>

  <img class="fig fragment" data-fragment-index="1" src="img/agent4dl/agent4dl.png" />
  <hr class="divider" />
  <p class="fragment" style="margin-top: -0.5em;">
    Agents formulate queries, assimilate information, click on documents, and
    assess if their information need is met inspired by human
    cognition.
  </p>

  <hr class="divider" />
  <p class="footnote fragment" data-fragment-index="1" style="margin-top: -1.5em;">
    <sup>8</sup>Shunyu Yao et al. "React: Synergizing reasoning and acting in language models". ICLR
    2023.
  </p>
</section>

<section id="agent4dl-profile" data-auto-animate>
  <h2>Agent Architecture</h2>
  <h4 style="margin-top: -0.5em; font-family: inherit;"><i>Profile Module</i></h4>
  <hr class="divider" />
  
  <p>
    To create realistic personas, the <b>Profile Module</b> models key
    academic traits:
  </p>
  <div class="column-layout">
    <div class="column-item">
      <ul>
        <li class="fragment" data-fragment-index="1">
          <b>Depth</b>: How thoroughly a user examines documents.
        </li>
        <li class="fragment" data-fragment-index="2">
          <b>Breadth</b>: The diversity of topics a user explores.
        </li>
      </ul>
    </div>
    <div class="column-item">
      <ul>
        <li class="fragment" data-fragment-index="3">
          <b>Recency Bias</b>: Preference for newer vs. older
          publications.
        </li>
        <li class="fragment" data-fragment-index="4">
          <b>Interdisciplinarity</b>: Tendency to cross academic fields.
        </li>
      </ul>
    </div>
  </div>
  <hr class="divider" />
  <p class="fragment" data-fragment-index="5">
    This allows for the simulation of diverse user types, from <i>"deep-diving
    specialists"</i> to <i>"quick-scanning generalists"</i>.
  </p>
</section>

<section id="agent4dl-memory" data-auto-animate>
  <h2>Agent Architecture</h2>
  <h4 style="margin-top: -0.5em; font-family: inherit;"><i>Memory Module</i></h4>
  <hr class="divider" />

  <p>
    Records experiences to inform future actions, capturing both facts and
    feelings.
  </p>
  <div class="column-layout">
    <div class="column-item fragment" data-fragment-index="1">
      <h4><span class="textBlue">Factual Memories</span></h4>
      <p>Concrete search behaviors:</p>
      <ul>
        <li>Queries used</li>
        <li>Documents viewed</li>
        <li>Citations made</li>
      </ul>
    </div>
    <div class="column-item fragment" data-fragment-index="2">
      <h4><span class="textRed">Emotional Memories</span></h4>
      <p>Psychological responses:</p>
      <ul>
        <li>Satisfaction with results</li>
        <li>Frustration with queries</li>
        <li>Information overload</li>
      </ul>
    </div>
  </div>
  <hr class="divider" />
  <p class="fragment" data-fragment-index="3">
    A <b>reflection</b> mechanism allows agents to evaluate their emotional
    state and adjust their strategy.
  </p>
</section>

<section id="agent4dl-interaction" data-auto-animate>
  <h2>Agent Architecture</h2>
  <h4 style="margin-top: -0.5em; font-family: inherit;"><i>Interaction Module</i></h4>
  <hr class="divider" />

  <p>Translates profiles and memories into concrete actions within the digital library environment.</p>
  <div class="column-layout fragment" data-fragment-index="1">
    <div class="column-item">
      <h4>Search-driven Actions</h4>
      <ul>
        <li>Formulate/refine queries</li>
        <li>Explore result lists</li>
        <li>View abstracts / download full texts</li>
      </ul>
    </div>
    <div class="column-item fragment" data-fragment-index="2">
      <h4>Emotion-driven Actions</h4>
      <ul>
        <li>Evaluate search experience</li>
        <li>Provide feedback on results</li>
        <li>Abandon the search session</li>
      </ul>
    </div>
  </div>
  <hr class="divider" />
  <p class="fragment" data-fragment-index="3">
    We used Chain-of-Thought (CoT) prompting to enhance the agent's emotional
    reasoning capabilities.
  </p>
</section>

<section id="agent4dl-results" data-auto-animate data-auto-animate-id="agent4dl">
  <h2>Framework Evaluation</h2>
  <h4 style="margin-top: -0.5em; font-family: inherit;"><i>Query reformulation</i></h4>
  <hr class="divider" />

  <p>
    How well do Agent4DL's generated queries match those of real users?
  </p>
  <img class="fig" src="img/gen_agents/agent4dl_consistency_results_out.svg" />
  <p class="caption">
    Query similarity metrics on an academic search logs dataset (Sowiport). Higher is better.
  </p>
  <hr class="divider" />
  <p class="fragment">
    Agent4DL achieves a high degree of semantic and lexical alignment with
    human queries.
  </p>
</section>

<section id="agent-eval3-setup" data-auto-animate data-auto-animate-id="agent4dl">
  <h2>Framework Evaluation</h2>
  <h4 style="margin-top: -0.5em; font-family: inherit;"><i>Simulation Expansion</i></h4>
  <hr class="divider" />

  <p>
    <b>Hypothesis:</b> <span class="textsc">Agent4DL</span> can be used to
    augment sparse datasets and improve model performance.
  </p>
  <hr class="divider" />
  <div class="fragment">
    <p><b>The Experiment:</b></p>
    <ol>
      <li>
        Start with a small baseline dataset (<b>500</b> real sessions).
      </li>
      <li>
        Generate <b>+500</b> new sessions with
        <span class="textsc">Agent4DL</span> using diverse academic profiles.
      </li>
      <li>
        Compare model performance when trained on the baseline vs. the
        augmented (<b>1000</b> session) dataset.
      </li>
    </ol>
  </div>
</section>

<section id="agent-eval3-results" data-auto-animate data-auto-animate-id="agent4dl">
  <h2>Framework Evaluation</h2>
  <h4 style="margin-top: -0.5em; font-family: inherit;"><i>Simulation Expansion</i></h4>
  <hr class="divider" />

  <img class="fig" src="img/agent_evaluation/expansion_results_out.svg" />
  <p class="caption">
    MRR score on the SUSS Session dataset.
  </p>
  <hr class="divider" />
  <p class="fragment">
    Augmenting the training data with
    <span class="textsc">Agent4DL</span> sessions leads to
    <b> performance gains (+8.9%)</b>, effectively addressing data
    scarcity.
  </p>
</section>

<section id="rag-limits" data-auto-animate data-auto-animate-id="personarag">
  <h2>Generative Agents</h2>
  <h4 style="margin-top: -0.5em; font-family: inherit;"><i>Simulation for Personalization</i></h4>
  <hr class="divider" />

  <p>
    Our work with <b>Agent4DL</b> shows we can model complex user search
    behaviors. <br /><span class="fragment" data-fragment-index="1">But, can we
      leverage this to create a <b>truly adaptive</b> search
      experience?</span>
  </p>
  
  <img class="fig fragment" data-fragment-index="2" src="img/agent4dl/personarag_2.png" style="margin-top: -0.5em;" />
</section>

<section id="personarag-intro" data-auto-animate data-auto-animate-id="personarag">
  <h2>Generative Agents</h2>
  <h4 style="margin-top: -0.5em; font-family: inherit;"><i>PersonaRAG</i></h4>
  <hr class="divider" />

  <p>
    <b>PersonaRAG</b><sup>9</sup> enhances RAG search by introducing a team of specialized agents
    that collaborate to model the user and personalize the response.
  </p>
  <img class="fig" src="img/gen_agents/personarag_architecture_out.svg" />
  <p class="caption">
    Agents communicate via a Global Message Pool to build a holistic user
    understanding and create a personalized response.
  </p>

  <hr class="divider" />
  <p class="footnote" style="margin-top: -0.5em;">
    <sup>9</sup>Saber Zerhoudi et al. "PersonaRAG: Enhancing Retrieval-Augmented Generation Systems with
    User-Centric Agents". SIGIR 2024.
  </p>
</section>

<section id="personarag-results" data-auto-animate data-auto-animate-id="personarag">
  <h2>Generative Agents</h2>
  <h4 style="margin-top: -0.5em; font-family: inherit;"><i>PersonaRAG</i></h4>
  <hr class="divider" />

  <div class="column-layout">
    <div class="column-item">
      <img class="fig" src="img/agent4dl/persona_02.png" style="margin-top: -1em;" />
    </div>
    <div class="column-item">
      <img class="fig" src="img/agent4dl/persona_04.png" style="height: 80%; margin-top: -1em;" />
    </div>
  </div>

</section>

<section id="agent4dl-summary">
  <h2>Summary</h2>
  <hr class="divider" />
  <ul>
    <li>
      We introduced <b>Agent4DL</b>, a generative agent that simulates academic search to produce <b>high-quality training data</b> for IR models.
    </li>
    <li>
      The agent's behavior shows <b>high fidelity</b> to human patterns in queries, clicks, and session length.
    </li>
    <li class="fragment">
      Agent-based simulators like <b>Agent4dl</b> enable <b>adaptive and personalized</b> retrieval by actively modeling user context and needs (<span class="textsc">PersonaRAG</span>).
    </li>
  </ul>
  <hr class="divider" />
  <div class="github-container">
    <img class="github-qr" src="img/agent4dl/agent4dl_github.png" />
    <a class="github-url" href="https://github.com/padas-lab-de/icadl24-agent4dl">padas-lab-de/icadl24-agent4dl</a>
  </div>
</section>