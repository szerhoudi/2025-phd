<!-- backup -->
<section class="sec-title" id="backup">
  <h2>
    <b>Backup slides</b>
  </h2>
</section>

<!-- Alignment Embedding -->
<section id="from-actions-to-queries">
  <h2>Simulating Queries: Focusing on Reformulation</h2>
  <hr class="divider" />

  <div class="custom-two-column">
    <div class="custom-col-40">
      <p>
        Modeling every user action—clicks, scrolls, hovers—is complex and often noisy.
      </p>
      <p class="fragment" data-fragment-index="1">
        We can simplify by focusing on the core signal of user intent: the <b>query sequence</b>.
      </p>
      <hr class="divider" />
      <p class="fragment" data-fragment-index="2">
        This abstracts away low-level interactions, reducing the simulation problem to modeling query transitions:
      </p>
      <p class="fragment highlight-blue" data-fragment-index="2" style="text-align: center; margin-top: 1em;">
        $P(q_{i+1} | q_i)$
      </p>
    </div>

    <div class="custom-col-60">
      <div class="fig fragment" data-fragment-index="1">
        <pre><code class="python" style="font-size: medium;" data-trim data-noescape data-line-numbers="|1,5,8">
ACTION QUERY   201  0   "how to look busy at work"
ACTION SERP    201  8   EXAMINE_SERP
ACTION CLICK   201  15  rank=2
ACTION ASSESS  201  92  duration=77s
ACTION QUERY   201  105 "ways to appear productive"
ACTION CLICK   201  110 rank=1
ACTION READ    201  180 duration=70s
ACTION QUERY   201  220 "best office productivity hacks"
[...]
        </code></pre>
      </div>
      <p class="caption">An example user interaction log.</p>
    </div>
  </div>
</section>


<section id="sim-queries-alignment" data-auto-animate data-auto-animate-id="sim-queries">
  <h2>Simulating Queries: Embedding Alignment</h2>
  <hr class="divider" />
  <p>
    Instead of modeling actions, we can directly simulate the
    <b>semantic evolution of queries</b>.
  </p>
  <p class="fragment" data-fragment-index="1">
    <b>Approach</b>: Learn a linear transformation
    <b class="fragment highlight-green" data-fragment-index="2">$W$</b>
    that maps a query's vector representation to the representation of the
    <b class="fragment highlight-green" data-fragment-index="2">next query</b>
    in the session.
  </p>
  <img class="fig fragment" data-fragment-index="2" src="img/user_simulation/embedding_alignment_out.svg" />
  <hr class="divider fragment" data-fragment-index="3" />
  <p class="fragment" data-fragment-index="3">
    This allows generating entire sessions of semantically coherent queries
    from an initial query.
  </p>
</section>


<section id="user-simulation-pipeline" data-auto-animate data-auto-animate-id="pipeline">
  <h2>Modeling Reformulation in Embedding Space</h2>
  <hr class="divider" />
  <p>
    Modeling $P(q_{i+1} | q_i)$ in the discrete space of words is intractable.
    <br />
    <b class="fragment">Solution:</b> Model the transition as a linear transformation in a
    continuous semantic space.
  </p>
  <hr class="divider" />
  <div class="fragment">
    <img class="fig" src="img/user_simulation/simulation_pipeline_out.svg" style="width: 90%" />
    <p class="caption">
      The full simulation pipeline for a single query reformulation.
    </p>
  </div>
</section>

<section id="user-simulation-embeddings" data-auto-animate data-auto-animate-id="pipeline">
  <h2>Modeling Reformulation in Embedding Space</h2>
  <hr class="divider" />
  <p>
    The quality of the simulation depends entirely on the quality of the
    <b>query embeddings</b>.
  </p>
  <hr class="divider" />
  <p>
    We use <span class="textsc">Skip-thought</span> embeddings trained on
    session logs ($q_{i-1} \leftarrow q_i \rightarrow q_{i+1}$).
  </p>
  <p class="fragment">
    This forces the model to learn <b>session-aware semantics</b>:
  </p>
  <ul class="fragment">
    <li>Embeddings capture not just a query's topic, but its typical
      <b>role and intent</b> within a search session.
    </li>
    <li>
      This is crucial for modeling realistic query *transitions*.
    </li>
  </ul>
</section>

<section id="user-simulation-evaluation">
  <h2>Evaluation: Beyond Relevance</h2>
  <hr class="divider" />
  <p>
    A good simulation must be more than just effective.
  </p>
  <p class="fragment">
    <b>Hypothesis:</b> Simulated sessions should be realistic in terms of both
    <b>performance</b> and <b>behavioral plausibility</b>.
  </p>
  <hr class="divider" />
  <div class="column-layout fragment">
    <div class="column-item">
      <h4>1. Performance</h4>
      <p>
        Does the simulation achieve a similar
        <b>cumulative gain (sDCG)</b> to real users over a session?
      </p>
    </div>
    <div class="column-item">
      <h4>2. Behavioral Plausibility</h4>
      <p>
        Does the simulation replicate the
        <b>cognitive effort trade-off</b> (querying vs. Browse) seen in
        humans?
      </p>
    </div>
  </div>
</section>

<section id="user-simulation-results-sdcg">
  <h2>Result 1: Cumulative Gain (sDCG)</h2>
  <hr class="divider" />
  <img class="fig" src="img/user_simulation/sdcg_plot_revised_out.svg" />
  <p class="caption">
    Our model (<span class="textsc">ST_EA</span>) closely tracks the
    performance of real users (<span class="textsc">UQV⁵</span>) and is
    competitive with a strong baseline.
  </p>
  <hr class="divider" />
  <p>
    <b>Takeaway:</b> The model is effective at generating query sequences
    that lead to high overall session performance.
  </p>
</section>


<!-- CACSM -->

<section id="cacsm-rnn-model" data-auto-animate>
  <h2>Approach 1: RNN-based User Model</h2>
  <hr class="divider" />
  <div class="column-layout">
    <div class="column-item c-wide">
      <p>
        An efficient model using a <b>Gated Recurrent Unit (GRU)</b> to process
        the sequence of user interaction embeddings.
      </p>
      <p class="fragment">
        The final hidden state of the GRU represents the user's current
        state $s_t$.
      </p>
      <p class="fragment">
        A feed-forward network then predicts the probability distribution over
        all potential next actions.
      </p>
      <p class="fragment">
        We enhance training with <b>negative sampling</b> to help the model
        better discriminate between likely and unlikely actions.
      </p>
    </div>
    <div class="column-item fragment">
      <img class="fig" src="img/cacsm_simulation/rnn_model_out.svg" />
      <p class="caption">High-level architecture of CACSM\(_{\texttt{UM}}\).</p>
    </div>
  </div>
</section>

<section id="cacsm-llm-model" data-auto-animate>
  <h2>Approach 2: LLM-based User Model</h2>
  <hr class="divider" />
  <div class="column-layout">
    <div class="column-item c-wide">
      <p>
        A powerful model that integrates the user state into a pretrained LLM
        (<b>T5-base</b>).
      </p>
      <p class="fragment">
        <b>Key Idea:</b> The user's cognitive state embedding is injected into
        each layer of the LLM via <b>cross-attention</b>.
      </p>
      <p class="fragment">
        This allows the LLM to generate personalized, state-aware predictions,
        going beyond just textual history.
      </p>
      <p class="fragment">
        We test both full fine-tuning and parameter-efficient
        <b>LoRA</b> tuning.
      </p>
    </div>
    <div class="column-item fragment">
      <img class="fig" src="img/cacsm_simulation/llm_model_out.svg" />
      <p class="caption">
        Injecting user state into an LLM via cross-attention.
      </p>
    </div>
  </div>
</section>




<!-- Evaluation -->
<section id="evaluation-methods-classification" data-auto-animate>
  <h2>The Turing Test</h2>
  <h4 style="margin-top: -0.5em; font-family: inherit;"><i>Classification-based Evaluation</i></h4>
  <hr class="divider" />
  
  <p>
    We train a machine learning classifier to distinguish between <b>real</b> and <b>simulated</b> session sequences.
  </p>
  
  <div style="text-align: center; margin: 1.5em 0;">
    <img class="fig" src="img/eval_simulation/ce_paradigm_out.svg" style="max-width: 65%;" />
  </div>
  
  <hr class="divider" />
  
  <div class="column-layout">
    <div class="column-item">
      <div class="c-wide">
        <p><b>Method:</b> Train a classifier on session sequences.</p>
        <p class="fragment"><b>Metrics:</b> Accuracy, Recall, Precision, F-Measure.</p>
      </div>
    </div>
    <div class="column-item fragment">
      <div class="c-wide">
        <p><b>Goal:</b> <span class="fragment highlight-red">Low F-Measure</span> is better.</p>
        <p class="fragment"><b>Intuition:</b> If the classifier is confused, the simulator is more realistic.</p>
      </div>
    </div>
  </div>
</section>

<section id="evaluation-methods-ks2" data-auto-animate>
  <h2>The Turing Test</h2>
  <h4 style="margin-top: -0.5em; font-family: inherit;"><i>Kolmogorov-Smirnov (KS-2) Test</i></h4>
  <hr class="divider" />
  
  <p>
    A <b>non-parametric test</b> to determine if two samples come from the same distribution.
  </p>
  
  <hr class="divider" />
  
  <div class="fragment" data-fragment-index="1">
    <p><b>KS-2 D-statistic:</b> Maximum absolute difference between empirical cumulative distribution functions.</p>
    <div style="text-align: center; margin: 1em 0;">
      $$D = \sup_x |F_1(x) - F_2(x)|$$
    </div>
  </div>
  
  <div class="fragment" data-fragment-index="2">
    <p><b>D-critical:</b> Critical value for statistical significance at confidence level $\alpha$.</p>
    <div style="text-align: center; margin: 1em 0;">
      $$D_{\text{crit}} = c(\alpha) \cdot \sqrt{\frac{n_1 + n_2}{n_1 n_2}}$$
    </div>
  </div>
  
  <hr class="divider" />
  
  <div class="fragment" data-fragment-index="3">
    <p><b>Decision rule:</b> If $D > D_{\text{crit}}$, samples differ significantly.</p>
    <p class="fragment" data-fragment-index="4">
      <b>Goal:</b> <span class="fragment highlight-red">Low D-statistic</span> means the distributions are closer.
    </p>
  </div>
</section>




<!-- Frechet Distance --> 
<section id="frechet-concept">
  <h2>Fréchet Distance: The Dog-on-a-Leash Metric</h2>
  <hr class="divider" />
  <div class="column-layout">
    <div class="column-item c-wide">
      <p>
        The Fréchet Distance measures the dissimilarity between two curves.
      </p>
      <p class="fragment">
        It is the <b>minimum leash length</b> required for a person on one
        curve and their dog on another to traverse their paths from start to
        finish.
      </p>
      <p class="fragment">
        Neither the person nor the dog can go backward to shorten the leash.
      </p>
      <hr class="divider" />
      <p class="fragment">
        It captures <b>both geometric and sequential dissimilarities</b>.
      </p>
    </div>
    <div class="column-item">
      <img class="fig" src="img/eval_simulation/leash_analogy_out.svg" />
      <p class="caption">
        The leash length must be long enough for the entire walk.
      </p>
    </div>
  </div>
</section>

<section id="frechet-application">
  <h2>From Trajectories to Search Sessions</h2>
  <hr class="divider" />
  <p>We can apply this concept to search sessions:</p>
  <ol>
    <li class="fragment" data-fragment-index="1">
      A search session is a <b>sequence of user actions</b> (queries,
      clicks).
    </li>
    <li class="fragment" data-fragment-index="2">
      We <b>embed each action</b> into a vector space using models like BERT.
      This transforms actions into points in a high-dimensional space.
    </li>
    <li class="fragment" data-fragment-index="3">
      The session now becomes a <b>trajectory</b> that we can compare.
    </li>
  </ol>
  <hr class="divider" />
  <p class="fragment" data-fragment-index="4">
    The <b>Sequential Fréchet Distance</b> averages this distance over many
    sessions:
  </p>
  <p class="eq fragment" data-fragment-index="4">
    $FD_{S_{\text{seq}}}^M = \frac{1}{|S|} \sum_{s_i \in S}
    FD(\mathbb{V}(R_{s_i}), \mathbb{V}(M(s_i)))$
  </p>
  <hr class="divider" />
  <p class="fragment" data-fragment-index="5">
    A <b class="textGreen">LOWER</b> Fréchet Distance (FD) score means the
    simulated session is <b class="textGreen">MORE SIMILAR</b> to the real
    one.
  </p>
</section>

<section id="frechet-setup">
  <h2>Experimental Setup</h2>
  <hr class="divider" />
  <p>Can Fréchet Distance correctly rank simulation models by their known complexity/realism?</p>
  <div class="column-layout">
    <div class="column-item">
      <h4>Dataset</h4>
      <p>TREC 2014 Session Track</p>
      <h4>Evaluation</h4>
      <p>Compare FD against traditional metrics (nDCG, ERR) and other session similarity metrics (sDCG, PSE).</p>
    </div>
    <div class="column-item">
      <h4>Simulation Models Compared</h4>
      (from simplest to most complex)
      <ul>
        <li>Position-Based Model (PBM)</li>
        <li>User Browse Model (UBM)</li>
        <li>Dependent Click Model (DCM)</li>
        <li>Dynamic Bayesian Network (DBN)</li>
        <li>Neural Click Model (NCM)</li>
        <li><b>SimIIR 2.0 Framework</b></li>
      </ul>
    </div>
  </div>
</section>

<section id="frechet-results-minimal">
  <h2>Results: Aligning with Traditional Metrics</h2>
  <hr class="divider" />
  <p>Evaluation on sessions with minimal interaction data.</p>
  <div class="fig r-stack">
    <img src="img/eval_simulation/table_minimal_out.svg" class="fragment fade-out" data-fragment-index="1" />
    <img src="img/eval_simulation/table_minimal_hl_out.svg" class="fragment fade-in" data-fragment-index="1" />
  </div>
  <hr class="divider" />
  <p class="fragment" data-fragment-index="1">
    As simulation quality improves (<b>nDCG/ERR increase</b>), the realism improves (<b>FD decreases</b>).
  </p>
  <p class="fragment" data-fragment-index="2">
    <b>Conclusion:</b> Fréchet Distance successfully ranks simulation models by their quality, aligning with established metrics.
  </p>
</section>

<section id="frechet-results-extensive">
  <h2>Results: Robustness with Complex Sessions</h2>
  <hr class="divider" />
  <p>FD remains a strong indicator of quality even with extensive interaction data.</p>
  <div class="column-layout">
    <div class="column-item">
      <img class="fig" src="img/eval_simulation/correlation_plot_out.svg" />
      <p class="caption">Strong negative correlation between nDCG and FD.</p>
    </div>
    <div class="column-item">
      <img class="fig" src="img/eval_simulation/table_kendall_out.svg" />
      <p class="caption">High rank correlation between full and partial sessions.</p>
    </div>
  </div>
  <hr class="divider" />
  <p><b>Conclusion:</b> FD is a stable and robust metric, effective for both simple and complex search scenarios.</p>
</section>

<section id="frechet-results-correlation">
  <h2>Results: Correlation with Other Similarity Metrics</h2>
  <hr class="divider" />
  <p>
    Fréchet Distance was compared against other state-of-the-art session similarity metrics.
  </p>
  <img class="fig" src="img/eval_simulation/table_corr_similarity_out.svg" />
  <hr class="divider" />
  <p>
    FD shows <b>strong, negative correlations</b> with established metrics like Session nDCG (sDCG) and Path-based Session Evaluation (PSE).
  </p>
  <p class="fragment">
    This validates FD as a legitimate measure of session similarity, capturing behavior consistent with other tools.
  </p>
</section>

<section id="frechet-discussion-features">
  <h2>Discussion: Sensitivity to Feature Extraction</h2>
  <hr class="divider" />
  <p>Does the way we embed sessions affect the evaluation?</p>
  <img class="fig" src="img/eval_simulation/feature_boxplot_out.svg" />
  <p class="caption">Distribution of FD scores for different session embedding methods.</p>
  <hr class="divider" />
  <p>
    The absolute FD score varies by method, but the <b>relative ranking</b> of simulation models remains largely consistent.
  </p>
  <p class="fragment">
    <b>Recommendation:</b> Use a consistent, powerful embedding method (e.g., BERT-based) when comparing simulation models with FD.
  </p>
</section>



<!-- Agent4DL --> 
<section id="agent4dl-profile" data-auto-animate data-auto-animate-id="architecture">
  <h2>Agent Architecture: <span class="textsc">Profile Module</span></h2>
  <hr class="divider" />
  <p>Defines an agent's academic identity and search style.</p>
  <div class="column-layout">
    <div class="column-item">
      <h4>Academic Traits</h4>
      <p>Quantifiable research behaviors:</p>
      <ul>
        <li><b>Depth:</b> Thoroughness of engagement.</li>
        <li><b>Breadth:</b> Diversity of topics explored.</li>
        <li><b>Recency Bias:</b> Preference for newer papers.</li>
        <li><b>Interdisciplinarity:</b> Tendency to cross fields.</li>
      </ul>
    </div>
    <div class="column-item">
      <h4>Research Interests</h4>
      <p>
        To capture interests, we use an LLM to summarize a sample of 10
        documents from a real user's history, creating a natural language
        profile.
      </p>
    </div>
  </div>
  <hr class="divider" />
  <p>
    This allows agents to exhibit consistent, personalized search patterns.
  </p>
</section>

<section id="agent-eval1-setup" data-auto-animate data-auto-animate-id="eval1">
  <h2>Evaluation 1: Search Simulation</h2>
  <hr class="divider" />
  <p>
    <b>Hypothesis:</b> Data generated by
    <span class="textsc">Agent4DL</span> can effectively train
    high-performing ranking models.
  </p>
  <hr class="divider" />
  <div class="fragment" style="text-align: center">
    <p>
      We train a <span class="textsc">RoBERTa</span> ranker on different
      datasets:
    </p>
    <p>
      <span class="fragment highlight-red" data-fragment-index="1">Real Data (SUSS, EconBiz)</span>
      <span class="fragment fade-in-then-out" data-fragment-index="1" style="margin: 0 1em; font-size: 2em">vs.</span>
      <span class="fragment highlight-green" data-fragment-index="1">Simulated Data (Agent4DL)</span>
    </p>
  </div>
  <hr class="divider" />
  <p class="fragment">
    Then, we evaluate its performance on a
    <b>human-annotated test set</b> for preference and relevance prediction
    tasks.
  </p>
</section>

<section id="agent-eval1-results" data-auto-animate data-auto-animate-id="eval1">
  <h2>Results: Search Simulation Performance</h2>
  <hr class="divider" />
  <p>Performance on the Preference Prediction task (higher is better).</p>
  <img class="fig" src="img/agent_evaluation/search_sim_results_out.svg" />
  <p class="caption">
    nDCG@3 scores on a real user benchmark.
  </p>
  <hr class="divider" />
  <p class="fragment">
    The model trained on
    <span class="textsc">Agent4DL</span> data
    <b class="textGreen">significantly outperforms</b> models trained on real
    user data.
  </p>
</section>

<section id="agent-eval2-setup" data-auto-animate data-auto-animate-id="eval2">
  <h2>Evaluation 2: Behavioral Consistency</h2>
  <hr class="divider" />
  <p>
    <b>Hypothesis:</b> <span class="textsc">Agent4DL</span> can maintain
    coherent preferences and mimic human search patterns.
  </p>
  <p class="fragment">
    We deconstruct and evaluate three core behaviors:
  </p>
  <div class="column-layout fragment">
    <div class="column-item" style="text-align: center">
      <h3 class="textBlue">Query Behavior</h3>
      <p>Similarity of generated vs. human queries.</p>
    </div>
    <div class="column-item" style="text-align: center">
      <h3 class="textGreen">Click Behavior</h3>
      <p>Accuracy of document selection.</p>
    </div>
    <div class="column-item" style="text-align: center">
      <h3 class="textRed">Stopping Behavior</h3>
      <p>Accuracy of session termination points.</p>
    </div>
  </div>
</section>

<section id="agent-eval2-q-results" data-auto-animate data-auto-animate-id="eval2">
  <h2>Results: Query Consistency</h2>
  <hr class="divider" />
  <img class="fig" src="img/agent_evaluation/query_consistency_results_out.svg" />
  <p class="caption">
    Similarity between agent-generated and real user queries.
  </p>
  <hr class="divider" />
  <p class="fragment">
    <span class="textsc">Agent4DL</span> generates queries that are
    <b>highly similar</b> to human queries, both thematically
    (<b>$\tau$=0.87</b>) and semantically (<b>BERTScore=0.83</b>).
  </p>
</section>

<section id="agent-eval2-cs-results" data-auto-animate data-auto-animate-id="eval2">
  <h2>Results: Click & Stopping Consistency</h2>
  <hr class="divider" />
  <div class="column-layout">
    <div class="column-item">
      <h4>Click Behavior</h4>
      <p>
        <span class="textsc">Agent4DL</span> is highly competitive with
        specialized, trained models like
        <span class="textsc">SimIIR 2.0</span>, without needing
        dataset-specific training.
      </p>
      <p class="eq fragment">
        Recall@10: <b><span class="textsc">Agent4DL</span> (65.6%)</b> vs.
        <span class="textsc">SimIIR 2.0</span> (59.1%)
      </p>
    </div>
    <div class="column-item">
      <h4>Stopping Behavior</h4>
      <p>
        <span class="textsc">Agent4DL</span> shows superior performance in
        deciding when to end a session.
      </p>
      <p class="eq fragment">
        Accuracy: <b><span class="textsc">Agent4DL</span> (84.1%)</b> vs.
        <span class="textsc">SimIIR 2.0</span> (81.4%)
      </p>
      <p class="eq fragment">
        Precision: <b><span class="textsc">Agent4DL</span> (82.9%)</b> vs.
        <span class="textsc">SimIIR 2.0</span> (70.1%)
      </p>
    </div>
  </div>
</section>



<!-- end: backup --> 